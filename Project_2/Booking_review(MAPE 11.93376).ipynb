{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n! pip install eng-spacysentiment\n! pip install polyglot\n! pip install afinn\n! pip install flair\n! pip install vaderSentiment","metadata":{"execution":{"iopub.status.busy":"2022-08-31T17:14:23.306714Z","iopub.execute_input":"2022-08-31T17:14:23.307173Z","iopub.status.idle":"2022-08-31T17:15:24.468260Z","shell.execute_reply.started":"2022-08-31T17:14:23.307083Z","shell.execute_reply":"2022-08-31T17:15:24.466616Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%%capture  \nimport numpy as np  \nimport pandas as pd  \nimport re  \nimport chardet.universaldetector\nimport calendar\nfrom IPython.display import display\npd.set_option(\"display.max_colwidth\", None)\nfrom rich import print    \nfrom pprint import pprint\nimport category_encoders as ce\nfrom sklearn import preprocessing\nfrom sklearn.feature_selection import f_classif\nfrom textblob import TextBlob, Blobber\nfrom textblob.sentiments import NaiveBayesAnalyzer\nfrom afinn import Afinn\nimport eng_spacysentiment\nfrom flair.models import TextClassifier\nfrom flair.data import Sentence\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nimport nltk  \nnltk.download([\n    \"names\",\n    \"stopwords\",\n    \"vader_lexicon\",\n])    \nfrom nltk.corpus import wordnet\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\n# Visualization\nimport matplotlib.pyplot as plt  \nimport seaborn as sns  \n%matplotlib inline  \nimport plotly  \nimport plotly.express as px  \nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff  \nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\n# Import geo services  \nimport geopy  \nfrom geopy import distance  \nfrom geopy.geocoders import Bing  # library import  \ngeolocator = Bing(\n    api_key=\"ArAEkjZybNV7puDe4lgO9FsX8VssJ57er2SG0SvcuN3YxL0bZ5U9wZUtPlddLrVx\"\n)  \nimport folium  \nfrom folium import Marker  \nfrom folium.plugins import MarkerCluster  \n\n# Modules for data split, train and evaluation of model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import metrics","metadata":{"collapsed":false,"pycharm":{"name":"#%%Capture\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:15:24.471229Z","iopub.execute_input":"2022-08-31T17:15:24.472482Z","iopub.status.idle":"2022-08-31T17:15:38.463629Z","shell.execute_reply.started":"2022-08-31T17:15:24.472432Z","shell.execute_reply":"2022-08-31T17:15:38.462591Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Set constants  \nRANDOM_SEED = 42  # random seed set\nDATA_DIR = \"../input/\"","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:15:38.465168Z","iopub.execute_input":"2022-08-31T17:15:38.466272Z","iopub.status.idle":"2022-08-31T17:15:38.471240Z","shell.execute_reply.started":"2022-08-31T17:15:38.466232Z","shell.execute_reply":"2022-08-31T17:15:38.470381Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Load data  \ndf_train = pd.read_csv(DATA_DIR + \"sf-booking/hotels_train.csv\")\ndf_test = pd.read_csv(DATA_DIR + \"sf-booking/hotels_test.csv\")\nsample_submission = pd.read_csv(DATA_DIR + \"sf-booking/submission.csv\")","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:15:38.474213Z","iopub.execute_input":"2022-08-31T17:15:38.474807Z","iopub.status.idle":"2022-08-31T17:15:44.961902Z","shell.execute_reply.started":"2022-08-31T17:15:38.474771Z","shell.execute_reply":"2022-08-31T17:15:44.960666Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Join train and test data for feature engineering  \ndf_train[\"sample\"] = 1  # train data mark  \ndf_test[\"sample\"] = 0  # test data mark  \ndf_test[\"reviewer_score\"] = 0  # the target variable in test data set 0  \n\ndata = pd.concat(                           # join datasets\n                 [df_train, df_test],       \n                 sort=False\n                 ).reset_index(drop=True)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:15:44.966358Z","iopub.execute_input":"2022-08-31T17:15:44.967020Z","iopub.status.idle":"2022-08-31T17:15:45.546063Z","shell.execute_reply.started":"2022-08-31T17:15:44.966969Z","shell.execute_reply":"2022-08-31T17:15:45.544778Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data.info()  ","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:15:45.548676Z","iopub.execute_input":"2022-08-31T17:15:45.549465Z","iopub.status.idle":"2022-08-31T17:15:45.778362Z","shell.execute_reply.started":"2022-08-31T17:15:45.549414Z","shell.execute_reply":"2022-08-31T17:15:45.777101Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### \"The Features Of The Hotels\"\nLook at missing data in **latitudes** and **longitudes** of hotels geo positions:","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# Missing data count  \ndef get_nan_cols(df):\n    \"\"\"\" Count missing data in dataframe by feature in percents \"\"\"  \n    \n    features_null_percent = df.isnull().mean().round(5) * 100  \n    cols_with_null = features_null_percent[\n                        features_null_percent > 0].sort_values(ascending=False)  \n    display(cols_with_null)  ","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:15:45.780048Z","iopub.execute_input":"2022-08-31T17:15:45.782460Z","iopub.status.idle":"2022-08-31T17:15:45.789065Z","shell.execute_reply.started":"2022-08-31T17:15:45.782419Z","shell.execute_reply":"2022-08-31T17:15:45.787563Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Look at missing data  \nprint(\"[magenta]Percents of missing data\")\nget_nan_cols(data)  \nnum = data[(data[\"lat\"].isna()) | (data[\"lng\"].isna())].shape[0]\nprint()\nprint(f\"[magenta]Number of rows with missing data: [magenta bold]{num}\")","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:15:45.791655Z","iopub.execute_input":"2022-08-31T17:15:45.792068Z","iopub.status.idle":"2022-08-31T17:15:46.106626Z","shell.execute_reply.started":"2022-08-31T17:15:45.792035Z","shell.execute_reply":"2022-08-31T17:15:46.105382Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"hotels_null = pd.read_csv(DATA_DIR + \"extradata-for-booking-reviews-competitions/long_lang.csv\", index_col=\"Unnamed: 0\")","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-08-31T17:15:46.108383Z","iopub.execute_input":"2022-08-31T17:15:46.108857Z","iopub.status.idle":"2022-08-31T17:15:46.119850Z","shell.execute_reply.started":"2022-08-31T17:15:46.108811Z","shell.execute_reply":"2022-08-31T17:15:46.118652Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Add filled data to main dataframe  \ndata = data.merge(hotels_null, how=\"left\", on=\"hotel_name\")  \ndata[\"lat\"] = data[\"lat_x\"].fillna(data[\"lat_y\"])  # fix latitude  \ndata[\"lng\"] = data[\"lng_x\"].fillna(data[\"lng_y\"])  # fix longitude  \n\n# Drop unnecessary columns  \ndata.drop(\n    columns=[\"lat_x\", \"lng_x\", \"lat_y\", \"lng_y\", \"hotel_address_y\"], \n    inplace=True\n)  \n\n# Some makeup))\ndata.rename(\n    columns={\"hotel_address_x\":\"hotel_address\"}, \n    inplace=True\n)    ","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:15:46.124462Z","iopub.execute_input":"2022-08-31T17:15:46.124865Z","iopub.status.idle":"2022-08-31T17:15:47.260730Z","shell.execute_reply.started":"2022-08-31T17:15:46.124829Z","shell.execute_reply":"2022-08-31T17:15:47.259400Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Unique hotels throughout dataframe","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# Filter unique hotels in dataframe\nhotels_unique = data[\n                     [\"hotel_address\", \"hotel_name\", \"lat\", \"lng\"]\n                    ].drop_duplicates()  \n\n# Add the map  \n#m_1 = folium.Map(\n#    tiles=\"openstreetmap\", \n#    zoom_start=5, \n#    location=[48.779124, 9.180090]\n#)\n\n# Add points to the map  \n#hotels = MarkerCluster()  \n#for idx, row in hotels_unique.iterrows():\n#    hotels.add_child(Marker([row[\"lat\"], row[\"lng\"]]))  \n#m_1.add_child(hotels)  \n#m_1  ","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:15:47.262352Z","iopub.execute_input":"2022-08-31T17:15:47.262821Z","iopub.status.idle":"2022-08-31T17:15:47.490049Z","shell.execute_reply.started":"2022-08-31T17:15:47.262773Z","shell.execute_reply":"2022-08-31T17:15:47.488765Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"There are 1494 unique hotels with unique addresses in 6 cities. 2 new features would be created:<br>\ncity of hotel and distance to centre of city from hotel<br>\nData of city centres was get from: https://simplemaps.com/data/world-cities","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# Set city of hotel\ndef get_city_hotel(address):\n    \"\"\"Get city from address\"\"\"  \n    \n    if \"United Kingdom\" in address:\n        city = \"London\"  \n    else:\n        city = address.split()[-2]  \n    return city\n\n# The city of the hotel feature\nhotels_unique[\"hotel_city\"] = hotels_unique[\n                                        \"hotel_address\"].apply(get_city_hotel)\n\n\n\n# Import data of the centres of the cities\ncentres_data = pd.read_csv(DATA_DIR + \"extradata-for-booking-reviews-competitions/centres.csv\")\nprint(\"[magenta]Dataset with centres coordinates\")\ndisplay(centres_data)  \n\n# Add centres of the cities  \nhotels_unique = hotels_unique.merge(centres_data, how=\"left\", on=\"hotel_city\")  \n\n# Create distance to centre feature\nhotels_unique[\"cent_dist\"] = hotels_unique.apply(\n                                            lambda x: \n                                            distance.distance(           \n                                                (x[\"lat\"], x[\"lng\"]),\n                                                (x[\"cent_lat\"], x[\"cent_lng\"])\n                                            ).km, \n                                            axis=1\n)  \n\n# Add data to main dataframe  \ndata = data.merge(hotels_unique, how=\"left\", on=[\"hotel_name\", \"lat\", \"lng\"])\n\n# Drop unnecessary columns \ndata.drop([\n    \"hotel_address_x\", \"hotel_address_y\", \"lat\", \"lng\", \"cent_lat\", \n    \"cent_lng\",\"hotel_country\"\n    ], \n    axis=1, \n    inplace=True\n)  \n\n# Add city names to distinguish hotels with similar names  \ndata[\"hotel_name\"] = data.apply(\n                            lambda x: \n                            (x[\"hotel_name\"] + \", \" + x[\"hotel_city\"]), \n                            axis=1\n)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:15:47.491645Z","iopub.execute_input":"2022-08-31T17:15:47.492039Z","iopub.status.idle":"2022-08-31T17:15:57.567800Z","shell.execute_reply.started":"2022-08-31T17:15:47.492003Z","shell.execute_reply":"2022-08-31T17:15:57.566323Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Encode hotel names","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# Choose unique hotels\nmask = data[\"sample\"] == 1 # as reviewers_score = 0 on sample = 0\nhotels_unique = data[mask].groupby(\n                                [\"hotel_name\", \"total_number_of_reviews\"]\n                                )[\"reviewer_score\"].agg(\n                                    [\"mean\"]\n                                    ).reset_index().rename(\n                                        columns={\"mean\":\"mean_rev_score\"}\n)  \n\nmask_hotel = (hotels_unique[\"mean_rev_score\"] >= 9) &\\\n                                (hotels_unique[\"total_number_of_reviews\"] > 350)  \nfiltered_hotels = hotels_unique[mask_hotel]\nprint(f\"[magenta]Number of filtered hotels: [magenta bold]{len(filtered_hotels)}\")\n\n# Create filtered hotel names feature\nhotels_unique[\"h_name_fix\"] = hotels_unique[\"hotel_name\"].apply(\n                                lambda name: name\n                                if name in filtered_hotels[\"hotel_name\"].values\n                                else \"other\"\n)  \n\nuh = hotels_unique[\"h_name_fix\"].nunique()  \nprint(f\"[magenta]Number of result hotels categories: [magenta bold]{uh}\")\n\n# Hotel names encode  \nhotels_unique[\"h_name_fix\"] = hotels_unique[\"h_name_fix\"].astype(\"category\")  # for encoding\n\nord_encoder = ce.OrdinalEncoder()  \nhotels_temp = ord_encoder.fit_transform(hotels_unique[[\"h_name_fix\"]])  \nhotels_temp.rename(columns = {\"h_name_fix\":\"hotel_enc\"}, inplace = True)  # to distinguish features  \nhotels_unique = pd.concat([hotels_unique, hotels_temp], axis=1)   \n\n# Drop unnecessary column  \nhotels_unique.drop([\"h_name_fix\", \"mean_rev_score\"], axis=1, inplace=True)  \n\n# Gather data into main dataframe  \ndata = data.merge(hotels_unique, how=\"left\", on=[\n                                    \"hotel_name\", \"total_number_of_reviews\"\n                                    ]\n)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:15:57.569404Z","iopub.execute_input":"2022-08-31T17:15:57.569795Z","iopub.status.idle":"2022-08-31T17:15:58.531028Z","shell.execute_reply.started":"2022-08-31T17:15:57.569750Z","shell.execute_reply":"2022-08-31T17:15:58.529560Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Encode hotel cities","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"markdown","source":"Divide cities into 3 groups by reviewers' scores:\n1. Barcelona & Vienna: 3\n2. Amsterdam & Milan: 2\n3. London & Paris: 1","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"def city_enc(city):\n    \"\"\" Encode cities \"\"\"\n    \n    if (city == \"Barcelona\") or (city == \"Vienna\"):\n        result = 3  \n    if (city == \"Amsterdam\") or (city == \"Milan\"):\n        result = 2  \n    if (city == \"London\") or (city == \"Paris\"):\n        result = 1  \n    return result\n\ndata[\"hotel_city_enc\"] = data[\"hotel_city\"].apply(city_enc)   ","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:15:58.532595Z","iopub.execute_input":"2022-08-31T17:15:58.533672Z","iopub.status.idle":"2022-08-31T17:15:58.820891Z","shell.execute_reply.started":"2022-08-31T17:15:58.533631Z","shell.execute_reply":"2022-08-31T17:15:58.820033Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"As we know average_score and reviewers score, so we can calculate their ratio.<br>\nIf the ratio is less than 1, then the average score of the hotel is growning, and we would mark it with 1.<br>\nIn other cases(ratio is equal or more than 1) it will be marked with 0.","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# Filter necessary data   \nmask = data[\"sample\"] == 1 # as reviewers_score = 0 on sample = 0\naverage_pivot = data[mask].groupby(\n                                [\"hotel_name\", \"average_score\"]\n                                )[\"reviewer_score\"].agg(\n                                    [\"mean\"]\n                                    ).reset_index().rename(\n                                        columns={\"mean\":\"mean_rev_score\"}\n)  \n\n# Calculate ratio of scores  \naverage_pivot[\"growth_index\"] = round(\n                                    average_pivot[\"average_score\"]/\n                                    average_pivot[\"mean_rev_score\"], \n                                    3\n)  \n\n# Mark growth  \naverage_pivot[\"hotel_growth_enc\"] = average_pivot[\"growth_index\"].apply(\n                                                    lambda x: 1 if x < 1 else 0\n)  \nprint(f\"[magenta]Result pivot_table\")\ndisplay(average_pivot)  \n\n# Drop unnecessary columns  \naverage_pivot.drop([\"mean_rev_score\", \"growth_index\"], axis=1, inplace=True)  \n\n# Add new feature to main dataframe  \ndata = data.merge(average_pivot, how=\"left\", on=[\"hotel_name\", \"average_score\"])  ","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:15:58.822068Z","iopub.execute_input":"2022-08-31T17:15:58.823029Z","iopub.status.idle":"2022-08-31T17:15:59.975343Z","shell.execute_reply.started":"2022-08-31T17:15:58.822972Z","shell.execute_reply":"2022-08-31T17:15:59.974254Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### \"Fantastic Reviewers and Where to Find Them\"","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"markdown","source":"We have features: **additional_number_of_scoring**(scores without reviews) and **total_number_of_reviews**(scores with reviews).<br>\nWell, scores without reviews are rather **suspicious**, so let's calculate the ratio of number of scores without reviews and number of all scores. ","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# Number of all scores\nall_scores = data[\"additional_number_of_scoring\"] + data[\"total_number_of_reviews\"]  \n\n# Calculate ratio of scores in percents  \ndata[\"score_ratio\"] = round(                                  \n                            data[\"additional_number_of_scoring\"]/all_scores, \n                            2\n                           ) * 100  \nprint(f\"[magenta]Unique ratio values\")\npprint(data[\"score_ratio\"].value_counts(), width=79, compact=True)  \n\n\"\"\" \n    There are different values from 2 percents to 28 percents.\n    I think it is very suspicious, when ratio was higher than 25 percents.\n    So let's divide ratios in 3 groups:\n    ratio <= 20%, 20 < ratio < 25, ratio >= 25%  \n    \n\"\"\"\n\n# Encode level of suspicion  \ndef ratio_encoding(ratio):\n    \"\"\" Encode level of suspicion \"\"\"  \n    \n    if ratio <= 20:\n        x = 0  \n    if (ratio > 20) and (ratio < 25):\n        x = 1  \n    if ratio >= 25:\n        x = 2  \n    return x  \n\n\ndata[\"suspicion_enc\"] = data[\"score_ratio\"].apply(ratio_encoding)  \n\ndata.drop([\"score_ratio\"], axis=1, inplace=True)  \n\nprint()  \nprint(f\"[magenta]Amount of hotels by level of suspicion\")\ndata[\"suspicion_enc\"].value_counts()  # amount of hotels by level of suspicion  ","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:15:59.976988Z","iopub.execute_input":"2022-08-31T17:15:59.977699Z","iopub.status.idle":"2022-08-31T17:16:00.598709Z","shell.execute_reply.started":"2022-08-31T17:15:59.977661Z","shell.execute_reply":"2022-08-31T17:16:00.597557Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# Review_date fix  \ndata[\"review_date\"] = pd.to_datetime(data[\"review_date\"])\ndata[\"review_month\"] = data[\"review_date\"].apply(lambda x: x.month)\n\n# Days_since_review fix  \ndata[\"days_since_review\"] = data[\"days_since_review\"].apply(\n                                               lambda x: int(x.split()[0])\n)  \n\n# Drop unnecessary columns\ndata.drop([\"review_date\"], axis=1, inplace=True)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:16:00.600134Z","iopub.execute_input":"2022-08-31T17:16:00.600510Z","iopub.status.idle":"2022-08-31T17:16:04.084014Z","shell.execute_reply.started":"2022-08-31T17:16:00.600477Z","shell.execute_reply":"2022-08-31T17:16:04.083128Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Now we will look at **reviewer nationality**.<br>\nReviewers' nationalities(countries) would be associated with their continents and thеn encoded.<br>\nThe data of countries and their continents was downloaded from: https://worldpopulationreview.com/country-rankings/list-of-countries-by-continent<br>\nand adapted for our purposes. ","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# Load data of countries by continents  \ncontinents = pd.read_csv(DATA_DIR + \"extradata-for-booking-reviews-competitions/continents.csv\")\nprint(\"[magenta]Data of countries by continents\")\ndisplay(continents)  \n\n# This is necessary as I found out later \ndata[\"reviewer_nationality\"] = data[\"reviewer_nationality\"].apply(\n                                                            lambda x: x.strip()\n)  \n\n# Add data to main dataframe  \ndata = data.merge(\n                  continents, \n                  how=\"left\", \n                  left_on=\"reviewer_nationality\", \n                  right_on=\"country\"\n)  \n\n# Now let's check our data\nprint(\"[magenta]Columns with nulls\")\nget_nan_cols(data)  \nprint()  \nprint(\"[magenta]Null data\")\ndisplay(data.loc[data[\"continent\"].isna(), \"reviewer_nationality\"].value_counts())\n\n# Oooops! We have NaN data for unrecognized countries\n# But the amount of missing values is rather small, \n# so just let's fill them with mode\ndata[\"continent\"].fillna(data[\"continent\"].mode()[0], inplace=True)\n\n# Now let's look at the distribution of reviewers score by continents\n#mask = data[\"sample\"] == 1 # as reviewers_score = 0 on sample = 0\n#fig = px.box(\n#      data[mask],\n#      x=\"reviewer_score\",\n#      y=\"continent\",\n#      color=\"continent\", \n#      width=1300,\n#      height=600,\n#      labels={\"reviewer_score\":\"Reviewers' Scores\"}\n#)  \n#fig.update_layout(\n#      font_family=\"Helvetica\",\n#      title={\n#            \"text\":\"Distribution of reviewers' scores by reviewers' continents\",\n#            \"x\":0.1, \"xanchor\":\"left\",\n#            \"y\":0.98, \"yanchor\":\"top\",\n#            },\n#      xaxis=dict(tickfont_size=14),\n#      yaxis=dict(tickfont_size=14, title=\"\"),\n#      legend=dict(\n#            title=\"continets:\", \n#            orientation=\"h\", \n#            y=1, yanchor=\"bottom\", \n#            x=1, xanchor=\"right\"\n#            )\n#)  \n#iplot(fig)  ","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:16:04.085442Z","iopub.execute_input":"2022-08-31T17:16:04.085801Z","iopub.status.idle":"2022-08-31T17:16:05.223264Z","shell.execute_reply.started":"2022-08-31T17:16:04.085767Z","shell.execute_reply":"2022-08-31T17:16:05.221958Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"As we can see above, there is very clear differentiation of reviewers scores by continents.<br>\nNow let's encode continents by scoring","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# Encode continents  \ndef continents_encode(continent):\n    \"\"\" Encode reviewers' continents \"\"\"  \n    \n    if continent == \"North America\":\n        x = 6  \n    if continent == \"Oceania\":\n        x = 5  \n    if continent == \"South America\":\n        x = 4  \n    if continent == \"Africa\":\n        x = 3  \n    if continent == \"Europe\":\n        x = 2  \n    if continent == \"Asia\":\n        x = 1\n    return x  \n\n\ndata[\"rev_continent_enc\"] = data[\"continent\"].apply(continents_encode) # encode reviewers' continents\n\n# Drop unnecessary columns\ndata.drop([\"reviewer_nationality\", \"country\", \"continent\"], axis=1, inplace=True)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:16:05.224667Z","iopub.execute_input":"2022-08-31T17:16:05.225579Z","iopub.status.idle":"2022-08-31T17:16:05.796364Z","shell.execute_reply.started":"2022-08-31T17:16:05.225538Z","shell.execute_reply":"2022-08-31T17:16:05.795392Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"**\"TAGS\"**","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# Tags overview  \ndef raw_tag_grab(tag):\n    \"\"\" Get list of tags from raw string \"\"\"  \n    \n    tag = tag.lower().lstrip(\"[' \").rstrip(\" ']\").replace(\"' \", \"\").replace(\" '\", \"\")\n    lst = tag.split(\",\")\n    tag_list = list(map(lambda t: t.strip(), lst))  \n    return tag_list  \n\n# Make column with list of tags  \ndata[\"tag_list\"] = data[\"tags\"].apply(raw_tag_grab)  \n\n# Make column with number of tags  \ndata[\"num_tag\"] = data[\"tag_list\"].apply(lambda tag_list: len(tag_list))  \n\n# Look at the structure of the tags  \nmn = data[\"num_tag\"].min()  \nprint(f\"[magenta]The minimum number of tags: [magenta bold]{mn}\")\nprint(data.loc[data[\"num_tag\"] == 1, \"tag_list\"])  \n\nprint()  \nmx = data[\"num_tag\"].max()  \nprint(f\"[magenta]The maximum number of tags: [magenta bold]{mx}\")\nprint(data.loc[data[\"num_tag\"] == 6, \"tag_list\"])  ","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:16:05.798063Z","iopub.execute_input":"2022-08-31T17:16:05.798437Z","iopub.status.idle":"2022-08-31T17:16:08.942202Z","shell.execute_reply.started":"2022-08-31T17:16:05.798401Z","shell.execute_reply":"2022-08-31T17:16:08.941072Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"**The maximum** number of tags is **6**. They have the structure:\n - with pet * \n - type of trip *\n - type of reviewer\n - room description *\n - amount of stayed nights *\n - hotel room was submitted from a mobile device *<br>\n\n\\* - *maybe nothing if less than the maximum*\n\n**The minimum** number of tags is **1**, there is only type of reviewer.<br>\nNow we can encode this tags","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# Encode with a pet tag  \ndef pet_tag_set(tag_list):\n    \"\"\" Encode pet_tag \"\"\"  \n    \n    if \"with a pet\" in tag_list:\n        pet = 1  \n        tag_list.remove(\"with a pet\")  \n    else:\n        pet = 0  \n    return pet  \n\n\n# Encode type of trip tag  \ndef trip_tag_set(tag_list):\n    \"\"\" Encode trip_tag \"\"\"  \n    \n    if \"leisure trip\" in tag_list:\n        trip = 2  \n        tag_list.remove(\"leisure trip\")  \n    elif \"business trip\" in tag_list:\n        trip = 1  \n        tag_list.remove(\"business trip\")  \n    else:\n        trip = 0  \n    return trip  \n\n\n# Encode number of stayed nights tag  \ndef nights_tag_set(tag_list):\n    \"\"\" Encode nights_tag \"\"\"  \n    \n    for tag in tag_list:\n        if re.match(r\"stayed\\s\\d+\\snights?\", tag):\n            nights = int(re.findall(r\".(\\d+).*\", tag)[0])  \n            tag_list.remove(tag)  \n        else:\n                nights = 0  \n    return nights  \n\n\n# Encode submitted from a mobile device tag  \ndef mob_dev_tag_set(tag_list):\n    \"\"\" Encode mob_dev_tag \"\"\"  \n    \n    if \"submitted from a mobile device\" in tag_list:\n        mob_dev = 1  \n        tag_list.remove(\"submitted from a mobile device\")  \n    else:\n        mob_dev = 0  \n    return mob_dev  \n\n\n# Apply functions and print some values  \ndata[\"pet_tag\"] = data[\"tag_list\"].apply(pet_tag_set)   \nsum_pet = data[\"pet_tag\"].sum()  \nprint(f\"[magenta]Number of reviewers with pet: [magenta bold]{sum_pet}\")\n\ndata[\"trip_tag\"] = data[\"tag_list\"].apply(trip_tag_set)  \nbus_trip = data.loc[data[\"trip_tag\"] == 1, \"trip_tag\"].count()  \nprint(f\"[magenta]Number of reviewers on a business trip: [magenta bold]{bus_trip}\")\n\ndata[\"nights_tag\"] = data[\"tag_list\"].apply(nights_tag_set)  \nnght = data.loc[data[\"nights_tag\"] == 1, \"nights_tag\"].count()  \nprint(f\"[magenta]Number of reviewers stayed for 1 night: [magenta bold]{nght}\")\n\ndata[\"mob_dev_tag\"] = data[\"tag_list\"].apply(mob_dev_tag_set)  \nmob_dev = data[\"mob_dev_tag\"].sum()  \nprint(\n    f\"[magenta]Number of reviewers submitted from a mobile device: \\\n[magenta bold]{mob_dev}\"\n)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:16:08.944055Z","iopub.execute_input":"2022-08-31T17:16:08.944430Z","iopub.status.idle":"2022-08-31T17:16:12.763896Z","shell.execute_reply.started":"2022-08-31T17:16:08.944396Z","shell.execute_reply":"2022-08-31T17:16:12.762733Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Get sets of unique reviewers' types and types of rooms  \nroom_set = set()  \ntraveller_set = set()  \n\ndef room_type_grab(tag_list):\n    \"\"\" Fill set of types of rooms tag \"\"\"  \n    global room_set  \n    if len(tag_list) > 1:\n        room_set.add(tag_list[1])  \n        \ndef trav_type_grab(tag_list):\n    \"\"\" Fill set of reviewers' types tag \"\"\"  \n    global traveller_set  \n    traveller_set.add(tag_list[0])  \n\n\n# Apply functions and print results\ndata[\"tag_list\"].apply(room_type_grab)  \nprint(f\"[magenta]Number of unique types of rooms: [magenta bold]{len(room_set)}\")\n\ndata[\"tag_list\"].apply(trav_type_grab)  \nprint(f\"[magenta]Unique reviewers' types:\\n[magenta bold]{traveller_set}\")\n\n# Create reviewer's type feature  \ndata[\"rev_type\"] = data[\"tag_list\"].apply(\n                                          lambda x: x[0] \n                                          if (x[0] in traveller_set) \n                                          else \"other\"\n)    \n\n# Create features from type_of_room tag  \ndef type_of_room_set(tag_list):\n    \"\"\" Create type of room feature \"\"\"  \n    \n    types = [\"premier\", \"superior\", \"deluxe\", \"classic\", \"guestroom\", \"standard\", \n            \"king\", \"queen\", \"club\", \"luxury\", \"suite\", \"executive\", \"junior\", \n            \"family\", \"basic\"]  \n    for tp in types:\n        if len(tag_list) > 1:\n            if tp in tag_list[1]:\n                return tp  \n            if (\"no window\" in tag_list[1]) or (\"without window\" in tag_list[1]):\n                return \"no window\"  \n    return \"other\"  \n\n# Create type of room feature\ndata[\"room_type\"] = data[\"tag_list\"].apply(type_of_room_set)  \n\n# Create double rooms feature  \ndata[\"roomX2\"] = data[\"tag_list\"].apply(\n                                        lambda x: 1                                \n                                        if ((len(x)>1) and (\n                                            (\"double\" in x[1]) or  \n                                            (\"twin\" in x[1]) or \n                                            (\"duplex\" in x[1])\n                                            )\n                                           ) \n                                        else 0\n)  \n\n# Create triple rooms feature  \ndata[\"roomX3\"] = data[\"tag_list\"].apply(\n                                        lambda x: 1                           \n                                        if ((len(x)>1) and (\"triple\" in x[1])) \n                                        else 0\n)  \n\n# Create quadruple rooms feature  \ndata[\"roomX4\"] = data[\"tag_list\"].apply(\n                                        lambda x: 1                              \n                                        if ((len(x)>1) and (\"quadruple\" in x[1])) \n                                        else 0\n)  \n\n# Create rooms with nice view feature  \ndata[\"with_view\"] = data[\"tag_list\"].apply(\n                                           lambda x: 1                          \n                                           if ((len(x)>1) and (\"view\" in x[1])) \n                                           else 0\n)  ","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:16:12.765621Z","iopub.execute_input":"2022-08-31T17:16:12.766005Z","iopub.status.idle":"2022-08-31T17:16:16.162665Z","shell.execute_reply.started":"2022-08-31T17:16:12.765970Z","shell.execute_reply":"2022-08-31T17:16:16.161596Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Encode reviewers' types and types of rooms  \n# Reviewers' types  \nrev_encoder = ce.OneHotEncoder(cols=[\"rev_type\"], use_cat_names=True)  \nrev_data= rev_encoder.fit_transform(data[\"rev_type\"])  \ndata = pd.concat([data, rev_data], axis=1)  \n\n# Types of rooms\nroom_encoder = ce.OneHotEncoder(cols=[\"room_type\"], use_cat_names=True)  \nroom_data = room_encoder.fit_transform(data[\"room_type\"])  \ndata = pd.concat([data, room_data], axis=1)  \n\n\n# Make heavy light  \ndata[\n     [\"hotel_city_enc\", \"hotel_growth_enc\", \"suspicion_enc\",\n      \"rev_continent_enc\", \"num_tag\", \"pet_tag\", \"trip_tag\", \"nights_tag\", \n      \"mob_dev_tag\", \"roomX2\", \"roomX3\", \"roomX4\", \"with_view\", \n      \"rev_type_couple\", \"rev_type_solo traveler\", \n      \"rev_type_family with young children\",\"rev_type_group\", \n      \"rev_type_family with older children\", \"rev_type_travelers with friends\", \n      \"room_type_suite\", \"room_type_standard\", \"room_type_other\", \n      \"room_type_superior\", \"room_type_king\", \"room_type_luxury\", \n      \"room_type_executive\", \"room_type_family\", \"room_type_deluxe\", \n      \"room_type_no window\", \"room_type_premier\", \"room_type_basic\", \n      \"room_type_classic\", \"room_type_queen\", \"room_type_guestroom\", \n      \"room_type_club\", \"room_type_junior\"]\n    ] = data[\n             [\"hotel_city_enc\", \"hotel_growth_enc\",\n              \"suspicion_enc\", \"rev_continent_enc\", \"num_tag\", \"pet_tag\", \n              \"trip_tag\", \"nights_tag\", \"mob_dev_tag\", \"roomX2\", \"roomX3\", \n              \"roomX4\", \"with_view\", \"rev_type_couple\", \"rev_type_solo traveler\", \n              \"rev_type_family with young children\",\"rev_type_group\", \n              \"rev_type_family with older children\", \n              \"rev_type_travelers with friends\", \"room_type_suite\", \n              \"room_type_standard\", \"room_type_other\", \"room_type_superior\", \n              \"room_type_king\", \"room_type_luxury\", \"room_type_executive\", \n              \"room_type_family\", \"room_type_deluxe\", \"room_type_no window\", \n              \"room_type_premier\", \"room_type_basic\", \"room_type_classic\", \n              \"room_type_queen\", \"room_type_guestroom\", \"room_type_club\", \n              \"room_type_junior\"]\n            ].astype(\"int8\")  ","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:16:16.164103Z","iopub.execute_input":"2022-08-31T17:16:16.164711Z","iopub.status.idle":"2022-08-31T17:16:20.281507Z","shell.execute_reply.started":"2022-08-31T17:16:16.164671Z","shell.execute_reply":"2022-08-31T17:16:20.280231Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Distribution of reviewers' scores by lengths of tags\n#mask = data[\"sample\"] == 1 # as reviewers_score = 0 on sample = 0  \n##fig = go.Figure()  \n#fig.add_trace(go.Box(\n#       y=data.loc[mask & (data[\"num_tag\"] == 1), \"reviewer_score\"], \n#       name=\" 1 tag \"\n#       )\n#),  \n#fig.add_trace(go.Box(\n#       y=data.loc[mask & (data[\"num_tag\"] == 2), \"reviewer_score\"], \n#       name=\" 2 tags \"\n#       )\n#),  \n#fig.add_trace(go.Box(\n#       y=data.loc[mask & (data[\"num_tag\"] == 3), \"reviewer_score\"], \n#       name=\" 3 tags \"\n#       )\n#),  \n#fig.add_trace(go.Box(\n#       y=data.loc[mask & (data[\"num_tag\"] == 4), \"reviewer_score\"], \n#       name=\" 4 tags \"\n#       )\n#),  \n#fig.add_trace(go.Box(\n#       y=data.loc[mask & (data[\"num_tag\"] == 5), \"reviewer_score\"], \n#       name=\" 5 tags \"\n#       )\n#),  \n#fig.add_trace(go.Box(\n#       y=data.loc[mask & (data[\"num_tag\"] == 6), \"reviewer_score\"], \n#       name=\" 6 tags \"\n#       )\n#)\n#fig.update_layout(\n#       font_family=\"Helvetica\",\n#       title={\n#              \"text\":\"Distribution of reviewers' scores by number of tags\",\n#              \"x\":0.07, \"xanchor\":\"left\",\n#              \"y\":0.9, \"yanchor\":\"top\",\n#              },\n#       xaxis=dict(tickfont_size=14),\n#       yaxis=dict(tickfont_size=14, title=\"Score\"),\n#       legend=dict(\n#              title=\"number of tags:\", \n#              orientation=\"h\", \n#              y=1, yanchor=\"bottom\", \n#              x=1, xanchor=\"right\"\n#              ),\n#       width= 1300,\n#       height= 600\n#)  \n#iplot(fig)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:16:20.284174Z","iopub.execute_input":"2022-08-31T17:16:20.285012Z","iopub.status.idle":"2022-08-31T17:16:20.291581Z","shell.execute_reply.started":"2022-08-31T17:16:20.284962Z","shell.execute_reply":"2022-08-31T17:16:20.290316Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"\n# There is direct correlation between reviewers' scores and number of tags\n# So, let's encode them  \ndef num_tag_enc(length):\n    \n    if length == 1:\n        result = 1  \n    elif length == 2:\n        result = 2  \n    elif (length >= 3) and (length <= 5):\n        result = 3  \n    elif length == 6:\n        result = 4  \n    return result  \n\ndata[\"num_tag_enc\"] = data[\"num_tag\"].apply(num_tag_enc)  ","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:16:20.293168Z","iopub.execute_input":"2022-08-31T17:16:20.293680Z","iopub.status.idle":"2022-08-31T17:16:20.566921Z","shell.execute_reply.started":"2022-08-31T17:16:20.293633Z","shell.execute_reply":"2022-08-31T17:16:20.565849Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Distribution of reviewers' scores by reviewers' types\n#mask = data[\"sample\"] == 1 # as reviewers_score = 0 on sample = 0  \n#rev_types_pivot = pd.pivot_table(\n#                                 data[mask],\n#                                 index=\"rev_type\", \n#                                 values=\"reviewer_score\", \n#                                 aggfunc=\"mean\"\n#                                ).reset_index()\n#\n#\n#fig = px.bar(\n#      rev_types_pivot,\n#      x=\"rev_type\",\n#      y=round(rev_types_pivot[\"reviewer_score\"], 3),\n#      color=\"rev_type\",\n#      labels={\"rev_type\":\"Reviewers' types\"},\n#      width=1000,\n#      height=600,\n#      text_auto=True\n#)\n#fig.update_layout(\n#      font_family=\"Helvetica\",\n#      title={\n#            \"text\":\"Distribution of reviewers' scores by reviewers' types\",\n#            \"x\":0.07, \"xanchor\":\"left\",\n#            \"y\":0.97, \"yanchor\":\"top\",\n#            },\n#      xaxis=dict(tickfont_size=14),\n#      yaxis=dict(tickfont_size=14, title=\"Scores\"),\n#      legend=dict(title=\"reviewers' types:\")\n#)  \n#fig.update_traces(textfont_size=14, textposition=\"outside\")  \n#iplot(fig)  ","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:16:20.568502Z","iopub.execute_input":"2022-08-31T17:16:20.568954Z","iopub.status.idle":"2022-08-31T17:16:20.575397Z","shell.execute_reply.started":"2022-08-31T17:16:20.568908Z","shell.execute_reply":"2022-08-31T17:16:20.574191Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"Mean of reviewers' scores are mostly similar for each type of travellers. But the **lowest values** are for **solo travellers**<br>\nand for **families with young children**. I think we have such result because people from this types have **less emotional involovement**<br>\nand so they are **more critical**.","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# Distribution of reviewers' scores by types of rooms\n#mask = data[\"sample\"] == 1 # as reviewers_score = 0 on sample = 0\n#room_types_pivot = pd.pivot_table(\n#                                  data[mask],\n#                                  index=\"room_type\", \n#                                  values=\"reviewer_score\", \n#                                  aggfunc=\"mean\"\n#                                 ).reset_index()\n#\n#\n#fig = px.bar(\n#       room_types_pivot,\n#       x=\"room_type\",\n#       y=round(room_types_pivot[\"reviewer_score\"], 2),\n#       color=\"room_type\",\n#       labels={\"room_type\":\"Types of Rooms\"},\n#       width=1300,\n#       height=500,\n#       text_auto=True\n#)\n#fig.update_layout(\n#       font_family=\"Helvetica\",\n#       title={\n#              \"text\":\"Distribution of reviewers' scores by types of rooms\",\n#              \"x\":0.07, \"xanchor\":\"left\",\n#              \"y\":0.97, \"yanchor\":\"top\",},\n#       xaxis=dict(tickfont_size=14),\n#       yaxis=dict(tickfont_size=14, title = \"Scores\"),\n#       legend=dict(title=\"types of rooms:\")\n#)  \n#fig.update_traces(textfont_size=14, textposition=\"outside\")  \n#iplot(fig) ","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:16:20.576720Z","iopub.execute_input":"2022-08-31T17:16:20.577079Z","iopub.status.idle":"2022-08-31T17:16:20.591032Z","shell.execute_reply.started":"2022-08-31T17:16:20.577045Z","shell.execute_reply":"2022-08-31T17:16:20.589745Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"On the plot above we can mark such a thing: **the lowest scores** are for tags, which charcterize the rooms like **basic, guestroom or room without window**.<br> On the other hand **the highest scores** are for tags, which tell us about **premium segment** of rooms.<br>\nI think, it’s pretty obvious.","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# Drop unnecessary columns  \ndata.drop(\n    [\"tags\" ,\"tag_list\", \"room_type\", \"rev_type\", \"num_tag\"], \n    axis=1, \n    inplace=True\n)  ","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:16:20.598733Z","iopub.execute_input":"2022-08-31T17:16:20.599479Z","iopub.status.idle":"2022-08-31T17:16:20.779651Z","shell.execute_reply.started":"2022-08-31T17:16:20.599437Z","shell.execute_reply":"2022-08-31T17:16:20.778494Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"### Reviews: \"No Negative\" and \"No Positive\"","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"%%time\n# Positive and negative review fix\n\ndef get_pos_rev(text):\n    \"\"\" Prepare positive review for sentiment analysis \"\"\"\n\n    neg_set = {                                                  # values mean negative\n        \"no positive\", \"na\", \"n a\", \"nil\", \"no\", \"non\",\n        \"nada\", \"nope\", \"zero\", \"none\", \"null\", \"none really\",\n        \"no thing\", \"nothing\", \"nothing really\"\n    }\n\n    # Correct some values for better analysis\n    text = text.lower().strip()\n    if len(text) <= 15:\n        text = str(TextBlob(text).correct()) # correct spell\n\n    for i in neg_set:\n        if text == i:\n            text = \"negative\"\n    return text\n\ndef get_neg_rev(text):\n    \"\"\" Prepare negative review for sentiment analysis \"\"\"\n\n    pos_set = {                                                  # values mean positive\n        \"no negative\", \"na\", \"n a\",  \"nil\", \"no\", \"non\",\n        \"nada\", \"nope\", \"zero\", \"none\", \"null\", \"no complaints\"\n        \"keinerlei beanstandung\", \"none really\", \"no thing\",\n        \"nothing\", \"nothing really\"\n    }\n\n    text = text.lower().strip()\n    if len(text) <= 15:\n        text = str(TextBlob(text).correct())  # correct spell\n\n    for i in pos_set:\n        if text == i:\n            text = \"positive\"\n    return text\n\n\ndata[\"positive_review_fix\"] = data[\"positive_review\"].apply(get_pos_rev)\ndata[\"negative_review_fix\"] = data[\"negative_review\"].apply(get_neg_rev)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:16:20.781348Z","iopub.execute_input":"2022-08-31T17:16:20.781701Z","iopub.status.idle":"2022-08-31T17:27:21.941524Z","shell.execute_reply.started":"2022-08-31T17:16:20.781670Z","shell.execute_reply":"2022-08-31T17:27:21.938659Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"%%time\n# Create a list of stopwords\ngarbage = nltk.corpus.stopwords.words(\"english\")\ngarbage.extend([w.lower() for w in nltk.corpus.names.words()])\n#from nltk.stem import WordNetLemmatizer \n#lemmatizer = WordNetLemmatizer()\n\ndef filter_review(text):\n    \"\"\" Filter review text \"\"\"\n\n    rev_str = str()\n    rev_lst = [word.strip() for word in nltk.word_tokenize(text)]\n    for word in rev_lst:\n        if word.isalpha() and (word not in garbage) and\\\n                (len(word) > 2) and ((word != \"\") or (word != \" \")):\n            #word = lemmatizer.lemmatize(word)  # get_wordnet_pos(word))\n            rev_str = rev_str + word + \" \"\n    return rev_str\n\ndata[\"positive_review_fixed\"] = data[\"positive_review_fix\"].apply(filter_review)\ndata[\"negative_review_fixed\"] = data[\"negative_review_fix\"].apply(filter_review)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:27:21.944340Z","iopub.execute_input":"2022-08-31T17:27:21.945529Z","iopub.status.idle":"2022-08-31T17:54:41.451665Z","shell.execute_reply.started":"2022-08-31T17:27:21.945464Z","shell.execute_reply":"2022-08-31T17:54:41.450316Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Some magic for better sentiment analysis\npositive_words = list()\nnegative_words = list()\n\n# Get unique positive words\ndef get_pos_words(text):\n    global positive_words\n    lst = text.split(\" \")\n    word_list = list(map(lambda w: w.strip(), lst))\n    for word in word_list:\n        positive_words.append(word)\n    return None\n\n# Get unique negative words\ndef get_neg_words(text):\n    global negative_words\n    lst = text.split(\" \")\n    word_list = list(map(lambda w: w.strip(), lst))\n    for word in word_list:\n        negative_words.append(word)\n    return None\n\nmask = data[\"sample\"] == 1\nmask1 = data[\"reviewer_score\"] >= 9.5\nmask2 = data[\"reviewer_score\"] <= 3.0\ndata.loc[(mask & mask1), \"positive_review_fixed\"].apply(get_pos_words)\ndata.loc[(mask & mask2), \"negative_review_fixed\"].apply(get_neg_words)\n\n# Create frequency distributions for each list of words\n# and remove common words for both\npositive_fd = nltk.FreqDist(positive_words)\nnegative_fd = nltk.FreqDist(negative_words)\n\nprint(\n    f\"[magenta]Initial number of words in positive_fd dictionary: \\\n[magenta bold]{len(positive_fd)}\"\n)\nprint(\n    f\"[magenta]Initial number of words in negative_fd dictionary: \\\n[magenta bold]{len(negative_fd)}\"\n)\n\ncommon_words = set(positive_fd).intersection(negative_fd)\nfor word in common_words:\n    del positive_fd[word]\n    del negative_fd[word]\n\nprint(\n    f\"[magenta]Number of words in common_words set: \\\n[magenta bold]{len(common_words)}\"\n)\nprint(\n    f\"[magenta]Result number of words in positive_fd dictionary: \\\n[magenta bold]{len(positive_fd)}\"\n)\nprint(\n    f\"[magenta]Result number of words in negative_fd dictionary: \\\n[magenta bold]{len(negative_fd)}\"\n)\n\n# Choose most common unique words in positive and negative reviews\ntop_neg = {word for word, count in negative_fd.most_common()}\ntop_pos = {word for word, count in positive_fd.most_common(len(top_neg))}","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:54:41.453376Z","iopub.execute_input":"2022-08-31T17:54:41.453722Z","iopub.status.idle":"2022-08-31T17:54:43.863453Z","shell.execute_reply.started":"2022-08-31T17:54:41.453691Z","shell.execute_reply":"2022-08-31T17:54:43.862220Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"%%time\n# Sentiment Intensity Analyzer with NLTK\n\nsia = SentimentIntensityAnalyzer()\nprint(\n    f\"[magenta]Default number of words in Sentiment Intensity Analyzer lexicon: [magenta bold]{len(sia.lexicon)}\"\n)\n\n# Update positive words\nfor word in top_pos:\n    if word in sia.lexicon:\n        sia.lexicon[word] += 0.5\n    else:\n        sia.lexicon[word] = 1\n\n# Update negative words\nfor word in top_neg:\n    if word in sia.lexicon:\n        sia.lexicon[word] -= 0.5\n    else:\n        sia.lexicon[word] = -1\n\nprint(\n    f\"[magenta]Number of words in Sentiment Intensity Analyzer lexicon after update: [magenta bold]{len(sia.lexicon)}\"\n)\n\n# Negative reviews Sentiment Intensity Analysis\ndata[\"negrev_sia_neg\"] = data[\"negative_review\"].apply(\n                                lambda x: sia.polarity_scores(x)[\"neg\"]\n)\ndata[\"negrev_sia_neu\"] = data[\"negative_review\"].apply(\n                                lambda x: sia.polarity_scores(x)[\"neu\"]\n)\ndata[\"negrev_sia_pos\"] = data[\"negative_review\"].apply(\n                                lambda x: sia.polarity_scores(x)[\"pos\"]\n)\ndata[\"negrev_sia_compound\"] = data[\"negative_review\"].apply(\n                                lambda x: sia.polarity_scores(x)[\"compound\"]\n)\n\n# Positive reviews Sentiment Intensity Analysis\ndata[\"posrev_sia_neg\"] = data[\"positive_review\"].apply(\n                                lambda x: sia.polarity_scores(x)[\"neg\"]\n)\ndata[\"posrev_sia_neu\"] = data[\"positive_review\"].apply(\n                                lambda x: sia.polarity_scores(x)[\"neu\"]\n)\ndata[\"posrev_sia_pos\"] = data[\"positive_review\"].apply(\n                                lambda x: sia.polarity_scores(x)[\"pos\"]\n)\ndata[\"posrev_sia_compound\"] = data[\"positive_review\"].apply(\n                                lambda x: sia.polarity_scores(x)[\"compound\"]\n)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T17:54:43.865008Z","iopub.execute_input":"2022-08-31T17:54:43.865821Z","iopub.status.idle":"2022-08-31T18:13:39.977874Z","shell.execute_reply.started":"2022-08-31T17:54:43.865784Z","shell.execute_reply":"2022-08-31T18:13:39.976625Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"%%time\n# Analyze data with Blobber\ntb = Blobber(analyzer=NaiveBayesAnalyzer())\n\ndata[\"posrev_tb_neg\"] = data[\"positive_review\"].apply(\n                                        lambda x: tb(x).sentiment.p_neg\n)\ndata[\"posrev_tb_negclass\"] = data[\"posrev_tb_neg\"].apply(\n                                        lambda x: 1 if x > 0.5 else 0\n)\ndata[\"negrev_tb_neg\"] = data[\"negative_review\"].apply(\n                                        lambda x: tb(x).sentiment.p_neg\n)\ndata[\"negrev_tb_negclass\"] = data[\"negrev_tb_neg\"].apply(\n                                        lambda x: 1 if x > 0.5 else 0\n)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T18:13:39.979439Z","iopub.execute_input":"2022-08-31T18:13:39.979776Z","iopub.status.idle":"2022-08-31T18:19:17.132350Z","shell.execute_reply.started":"2022-08-31T18:13:39.979744Z","shell.execute_reply":"2022-08-31T18:19:17.131314Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"%%time\n# Count ratio between number of most common words and all words in review\ndef get_positive_word_ratio(text):\n    \"\"\" Ratio with most common positive words \"\"\"\n\n    wrd_lst = [word.strip() for word in nltk.word_tokenize(text)]\n    lngth = len(wrd_lst)\n    wrd_cnt = 0\n    if lngth == 0:\n        return 0\n    for i in top_pos:\n        if i in wrd_lst:\n            wrd_cnt += 1\n    return wrd_cnt / lngth\n\n\ndata[\"pos_pos_words_ratio\"] = data[\"positive_review_fixed\"].apply(\n                                                        get_positive_word_ratio\n)\ndata[\"neg_pos_words_ratio\"] = data[\"negative_review_fixed\"].apply(\n                                                        get_positive_word_ratio\n)\n\ndef get_negative_word_ratio(text):\n    \"\"\" Ratio with most common negative words \"\"\"\n\n    wrd_lst = [word.strip() for word in nltk.word_tokenize(text)]\n    lngth = len(wrd_lst)\n    wrd_cnt = 0\n    if lngth == 0:\n        return 0\n    for i in top_neg:\n        if i in wrd_lst:\n            wrd_cnt += 1\n    return wrd_cnt / lngth\n\n\ndata[\"pos_neg_words_ratio\"] = data[\"positive_review_fixed\"].apply(\n                                                        get_negative_word_ratio\n)\ndata[\"neg_neg_words_ratio\"] = data[\"negative_review_fixed\"].apply(\n                                                        get_negative_word_ratio\n)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T18:19:17.133861Z","iopub.execute_input":"2022-08-31T18:19:17.134915Z","iopub.status.idle":"2022-08-31T18:36:10.087335Z","shell.execute_reply.started":"2022-08-31T18:19:17.134871Z","shell.execute_reply":"2022-08-31T18:36:10.086132Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"%%time\n# Count polarity and subjectivity with TextBlob\ndata[\"negrev_tb_pol\"] = data[\"negative_review_fix\"].apply(\n                                    lambda x: TextBlob(x).sentiment.polarity\n)\ndata[\"negrev_tb_sub\"] = data[\"negative_review_fix\"].apply(\n                                    lambda x: TextBlob(x).sentiment.subjectivity\n)\ndata[\"posrev_tb_pol\"] = data[\"positive_review_fix\"].apply(\n                                    lambda x: TextBlob(x).sentiment.polarity\n)\ndata[\"posrev_tb_sub\"] = data[\"positive_review_fix\"].apply(\n                                    lambda x: TextBlob(x).sentiment.subjectivity\n)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T20:39:32.103695Z","iopub.execute_input":"2022-08-31T20:39:32.104173Z","iopub.status.idle":"2022-08-31T20:48:03.880086Z","shell.execute_reply.started":"2022-08-31T20:39:32.104135Z","shell.execute_reply":"2022-08-31T20:48:03.878830Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"%%time\n# Afinn text analyzer\n\ndata[\"negative_review_tmp\"] = data[\"negative_review\"].apply(\n                                        lambda x: x.replace(\"No Negative\", \"\")\n)\ndata[\"positive_review_tmp\"] = data[\"positive_review\"].apply(\n                                        lambda x: x.replace(\"No Positive\", \"\")\n)\n\nafinn = Afinn()\ndata[\"review_sum\"] = data[\"negative_review_tmp\"] + \\\n                                            \" \" + data[\"positive_review_tmp\"]\ndata[\"afinn_score\"] = data[\"review_sum\"].apply(lambda x: afinn.score(x))","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T18:44:41.471473Z","iopub.execute_input":"2022-08-31T18:44:41.472048Z","iopub.status.idle":"2022-08-31T18:54:43.212623Z","shell.execute_reply.started":"2022-08-31T18:44:41.472015Z","shell.execute_reply":"2022-08-31T18:54:43.211398Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"%%time\n# SpaCy sentiment analysis\nnlp = eng_spacysentiment.load()\ndata[\"posrev_sc_pos\"] = data[\"positive_review\"].apply(lambda x: nlp(x).cats[\"positive\"])\ndata[\"negrev_sc_neg\"] = data[\"negative_review\"].apply(lambda x: nlp(x).cats[\"negative\"])","metadata":{"execution":{"iopub.status.busy":"2022-08-31T18:54:43.214071Z","iopub.execute_input":"2022-08-31T18:54:43.214457Z","iopub.status.idle":"2022-08-31T19:43:08.912399Z","shell.execute_reply.started":"2022-08-31T18:54:43.214423Z","shell.execute_reply":"2022-08-31T19:43:08.911175Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"#from flair.models import TextClassifier\n#from flair.data import Sentence\n\n#classifier = TextClassifier.load('en-sentiment')\ndef flair_sentiment_get(text):\n    \n    sentence = Sentence(text)\n    classifier.predict(sentence)\n    if len(sentence.labels) > 0:\n        if sentence.labels[0].value == \"NEGATIVE\":\n            return -abs(sentence.labels[0].score)\n        else:\n            return sentence.labels[0].score\n    else:\n        return 0\n\n\ndata[\"posrev_fl_sent\"] = data[\"positive_review\"].apply(flair_sentiment_get)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndata[\"negrev_fl_sent\"] = data[\"negative_review\"].apply(flair_sentiment_get)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nanalyzer = SentimentIntensityAnalyzer()\n\n# Negative reviews Sentiment Intensity Analysis\ndata[\"negrev_vdr_neg\"] = data[\"negative_review_fix\"].apply(\n                                lambda x: analyzer.polarity_scores(x)[\"neg\"]\n)\ndata[\"negrev_vdr_neu\"] = data[\"negative_review_fix\"].apply(\n                                lambda x: analyzer.polarity_scores(x)[\"neu\"]\n)\ndata[\"negrev_vdr_pos\"] = data[\"negative_review_fix\"].apply(\n                                lambda x: analyzer.polarity_scores(x)[\"pos\"]\n)\ndata[\"negrev_vdr_compound\"] = data[\"negative_review_fix\"].apply(\n                                lambda x: analyzer.polarity_scores(x)[\"compound\"]\n)\n\n# Positive reviews Sentiment Intensity Analysis\ndata[\"posrev_vdr_neg\"] = data[\"positive_review_fix\"].apply(\n                                lambda x: analyzer.polarity_scores(x)[\"neg\"]\n)\ndata[\"posrev_vdr_neu\"] = data[\"positive_review_fix\"].apply(\n                                lambda x: analyzer.polarity_scores(x)[\"neu\"]\n)\ndata[\"posrev_vdr_pos\"] = data[\"positive_review_fix\"].apply(\n                                lambda x: analyzer.polarity_scores(x)[\"pos\"]\n)\ndata[\"posrev_vdr_compound\"] = data[\"positive_review_fix\"].apply(\n                                lambda x: analyzer.polarity_scores(x)[\"compound\"]\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T00:23:24.375324Z","iopub.execute_input":"2022-09-01T00:23:24.376493Z","iopub.status.idle":"2022-09-01T00:35:59.895593Z","shell.execute_reply.started":"2022-09-01T00:23:24.376443Z","shell.execute_reply":"2022-09-01T00:35:59.894062Z"},"trusted":true},"execution_count":201,"outputs":[]},{"cell_type":"code","source":"%%capture\n#! pip install polyglot\n#! pip install icu\n\n#! pip install pyicu\n\n#! pip install pycld2\n\n#! pip install morfessor","metadata":{"execution":{"iopub.status.busy":"2022-08-31T19:43:08.913725Z","iopub.execute_input":"2022-08-31T19:43:08.914528Z","iopub.status.idle":"2022-08-31T19:43:08.921905Z","shell.execute_reply.started":"2022-08-31T19:43:08.914490Z","shell.execute_reply":"2022-08-31T19:43:08.920388Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"#! pip install -U git+https://github.com/aboSamoor/polyglot.git@master","metadata":{"execution":{"iopub.status.busy":"2022-08-31T19:43:08.923867Z","iopub.execute_input":"2022-08-31T19:43:08.924630Z","iopub.status.idle":"2022-08-31T19:43:08.933315Z","shell.execute_reply.started":"2022-08-31T19:43:08.924581Z","shell.execute_reply":"2022-08-31T19:43:08.932102Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"#from polyglot.downloader import downloader\n#print(downloader.supported_languages_table(\"sentiment2\", 3))","metadata":{"execution":{"iopub.status.busy":"2022-08-31T19:43:08.935058Z","iopub.execute_input":"2022-08-31T19:43:08.935528Z","iopub.status.idle":"2022-08-31T19:43:08.944090Z","shell.execute_reply.started":"2022-08-31T19:43:08.935493Z","shell.execute_reply":"2022-08-31T19:43:08.942904Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"#from polyglot.text import Text\n#from polyglot.detect import Detector, Language\n#text = Text(\"The movie was really good.\")\n#text.polarity","metadata":{"execution":{"iopub.status.busy":"2022-08-31T19:43:08.945711Z","iopub.execute_input":"2022-08-31T19:43:08.946078Z","iopub.status.idle":"2022-08-31T19:43:08.954966Z","shell.execute_reply.started":"2022-08-31T19:43:08.946044Z","shell.execute_reply":"2022-08-31T19:43:08.953672Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"### Reviews: \"The Number\"\nCorrelation of number of words in reviews and reviewers' scores","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"#mask = data[\"sample\"] == 1 # as reviewers_score = 0 on sample = 0\n#data_grp = data[mask].groupby([\"reviewer_score\"])[[\n#                        \"review_total_negative_word_counts\",\n#                        \"review_total_positive_word_counts\"\n#                        ]].agg({\n#                            \"review_total_negative_word_counts\":[\"max\", \"mean\"],\n#                           \"review_total_positive_word_counts\":[\"max\", \"mean\"],\n#                            }).reset_index()\n\n#nw_max = list(data_grp[\"review_total_negative_word_counts\"][\"max\"].values)\n#nw_mean = list(round(data_grp[\"review_total_negative_word_counts\"][\"mean\"]).values)\n\n#pw_max = list(data_grp[\"review_total_positive_word_counts\"][\"max\"].values)\n#pw_mean = list(round(data_grp[\"review_total_positive_word_counts\"][\"mean\"]).values)\n\n#scores = list(map(str, data_grp[\"reviewer_score\"].values))","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T19:43:08.956548Z","iopub.execute_input":"2022-08-31T19:43:08.956899Z","iopub.status.idle":"2022-08-31T19:43:08.966285Z","shell.execute_reply.started":"2022-08-31T19:43:08.956867Z","shell.execute_reply":"2022-08-31T19:43:08.965106Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# Plot the mean and the maximum of negative and positive words counts\n#fig = make_subplots(rows=2, cols=2, specs=[[{'type': 'polar'}]*2]*2)\n#fig.add_trace(go.Scatterpolar(\n#    name = \"Mean negative words count\",\n#    r = nw_mean,\n#    theta = scores,\n#), 1, 1)\n#fig.add_trace(go.Scatterpolar(\n#    name = \"Max negative words count\",\n#    r = nw_max,\n#    theta = scores,\n#), 2, 1)\n#fig.add_trace(go.Scatterpolar(\n#    name = \"Mean positive words count\",\n#    r = pw_mean,\n#    theta = scores,\n#), 1, 2)\n#fig.add_trace(go.Scatterpolar(\n#    name = \"Max positive words count\",\n#    r = pw_max,\n#    theta = scores,\n#), 2, 2)\n#fig.update_traces(fill='toself')\n#fig.update_layout(\n#    font_family=\"Helvetica\",\n#    title={\n#        \"text\":\"Correlation of words count and scores\",\n#        \"x\":0.45, \"xanchor\":\"center\"\n#        },\n#    height=1000,\n#        polar = dict(\n#        radialaxis_angle = 90,\n#        angularaxis = dict(\n#            direction = \"clockwise\",\n#            period = 6)\n#    ),\n#    polar2 = dict(\n#        radialaxis_angle = 90,\n#        angularaxis = dict(\n#            direction = \"clockwise\",\n#            period = 6),\n#    ),\n#    polar3 = dict(\n#        radialaxis_angle = 90,\n#        angularaxis = dict(\n#            direction = \"clockwise\",\n#            period = 6)\n#    ),\n#    polar4 = dict(\n#        radialaxis_angle = 90,\n#        angularaxis = dict(\n#            direction = \"clockwise\",\n#            period = 6)\n#    )\n#)\n#iplot(fig)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T19:43:08.967971Z","iopub.execute_input":"2022-08-31T19:43:08.968362Z","iopub.status.idle":"2022-08-31T19:43:08.981890Z","shell.execute_reply.started":"2022-08-31T19:43:08.968295Z","shell.execute_reply":"2022-08-31T19:43:08.980760Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"As we can see above, there are two types of correlations:<br>\n - positive correlation for positive words count(as the **larger** number of **positive** words the **higher score**)\n - negative correlation for negative words count(as the **larger** number of **negative** words the **lower score**)\n\nThis is obvious enough.<br>\nSo, we can make new feature: difference words. It will be normalized difference of numbers of positive and negative words.","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# Count difference of numbers of positive and negative words\ndata[\"diff_words\"] = data[\"review_total_positive_word_counts\"] -\\\n                                 data[\"review_total_negative_word_counts\"]\n\n# Normalize difference\nmm_scaler = preprocessing.MinMaxScaler()\ndata[\"diff_words_norm\"] = pd.DataFrame(\n    mm_scaler.fit_transform(pd.DataFrame(data[\"diff_words\"])),\n    columns=[\"diff_words\"]\n)\n\n# Positive words prevalence marker\ndata[\"pos_words_marker\"] = data[\"diff_words\"].apply(lambda x: 1 if x > 0 else 0)\n\n# Number of positive words to all words ratio\ndata[\"word_counts_sum\"] = data[\"review_total_positive_word_counts\"] +\\\n                                    data[\"review_total_negative_word_counts\"]\n\n# If sum of words is 0, ratio will be equal 0.5\ndata[\"pos_words_ratio\"] = data.apply(\n                            lambda x: 0.5\n                            if x[\"word_counts_sum\"] == 0\n                            else x[\"review_total_positive_word_counts\"] / \\\n                                                        x[\"word_counts_sum\"],\n                            axis=1\n)\n\n# Drop unnecessary columns\ndata.drop([\"diff_words\", \"word_counts_sum\"], axis=1, inplace=True)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T19:43:08.983917Z","iopub.execute_input":"2022-08-31T19:43:08.984286Z","iopub.status.idle":"2022-08-31T19:43:23.340679Z","shell.execute_reply.started":"2022-08-31T19:43:08.984240Z","shell.execute_reply":"2022-08-31T19:43:23.339578Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"We shall **not change** feature **'total_number_of_reviews_reviewer_has_given'**, because it is numeric and has less then 200 unique values, so **we can use it as it is**.","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"#pd.set_option('display.max_rows', 10)\n#**********************************************************************72****79","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T19:43:23.342347Z","iopub.execute_input":"2022-08-31T19:43:23.342719Z","iopub.status.idle":"2022-08-31T19:43:23.347190Z","shell.execute_reply.started":"2022-08-31T19:43:23.342686Z","shell.execute_reply":"2022-08-31T19:43:23.346032Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"get_nan_cols(data)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":202,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":203,"outputs":[]},{"cell_type":"code","source":"# Now let's create a copy of dataset to get ready,\n# if something would go wrong\ndf_cp = data.copy()","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T00:36:36.392742Z","iopub.execute_input":"2022-09-01T00:36:36.394197Z","iopub.status.idle":"2022-09-01T00:36:36.728441Z","shell.execute_reply.started":"2022-09-01T00:36:36.394112Z","shell.execute_reply":"2022-09-01T00:36:36.727129Z"},"trusted":true},"execution_count":204,"outputs":[]},{"cell_type":"code","source":"# Delete nonnumeric data\n\nprint(\n    f\"[magenta]Initial number of features: [magenta bold]{len(df_cp.columns)-2}\"\n)\n\nobject_columns = [col for col in df_cp.columns if df_cp[col].dtypes == \"object\"]\n\ndf_cp.drop(object_columns, axis = 1, inplace=True)\n\nprint()\nprint(\n    f\"[magenta]Number of features after deleting nonnumeric columns: \\\n[magenta bold]{len(df_cp.columns)-2}\"\n)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T00:36:42.052765Z","iopub.execute_input":"2022-09-01T00:36:42.053447Z","iopub.status.idle":"2022-09-01T00:36:42.210812Z","shell.execute_reply.started":"2022-09-01T00:36:42.053406Z","shell.execute_reply":"2022-09-01T00:36:42.209482Z"},"trusted":true},"execution_count":205,"outputs":[]},{"cell_type":"markdown","source":"Now check data for **multicollinearity**.<br>\nThere are two types of data: **numerical** and **categorical**, so use different methods for multicollinearity counting.<br>\nDivide data into two groups.","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# Numerical data\nnum_feats = [\n    \"review_total_negative_word_counts\", \"review_total_positive_word_counts\", \n    \"days_since_review\", \"cent_dist\", \"total_number_of_reviews_reviewer_has_given\", \n    \"negrev_sia_neg\", \"negrev_sia_neu\", \"negrev_sia_pos\", \"negrev_sia_compound\", \n    \"posrev_sia_neg\", \"posrev_sia_neu\", \"posrev_sia_pos\", \"posrev_sia_compound\", \n    \"negrev_tb_pol\", \"posrev_tb_pol\", \"posrev_tb_neg\", \"posrev_tb_negclass\",\n    \"negrev_tb_neg\", \"negrev_tb_negclass\", \"afinn_score\", \"diff_words_norm\",\n    \"pos_words_marker\", \"pos_words_ratio\", \"posrev_tb_sub\", \"negrev_tb_sub\",\n    \"pos_pos_words_ratio\", \"pos_neg_words_ratio\", \"neg_pos_words_ratio\",\n    \"neg_neg_words_ratio\", \"posrev_sc_neg\", \"negrev_sc_neg\",\n    \"negrev_vdr_neg\", \"negrev_vdr_neu\", \"negrev_vdr_pos\", \"negrev_vdr_compound\",\n    \"posrev_vdr_neg\", \"posrev_vdr_neu\", \"posrev_vdr_pos\", \"posrev_vdr_compound\",\n]\n\n# Categorical data\ncat_feats = [\n    \"additional_number_of_scoring\", \"average_score\", \"total_number_of_reviews\",\n    \"hotel_enc\", \"hotel_city_enc\", \"hotel_growth_enc\", \"suspicion_enc\",\n    \"rev_continent_enc\", \"pet_tag\", \"trip_tag\", \"nights_tag\", \"mob_dev_tag\",\n    \"roomX2\", \"roomX3\", \"roomX4\", \"with_view\", \"rev_type_couple\",\n    \"rev_type_solo traveler\", \"rev_type_family with young children\",\n    \"rev_type_group\", \"rev_type_family with older children\", \n    \"rev_type_travelers with friends\", \"room_type_suite\", \"room_type_standard\",\n    \"room_type_other\", \"room_type_superior\", \"room_type_king\", \"room_type_luxury\",\n    \"room_type_executive\", \"room_type_family\", \"room_type_deluxe\", \n    \"room_type_no window\", \"room_type_premier\", \"room_type_basic\", \n    \"room_type_classic\", \"room_type_queen\", \"room_type_guestroom\", \n    \"room_type_club\", \"room_type_junior\", \"num_tag_enc\", \"review_month\"\n]\n\nprint(\n    f\"[magenta]Number of features with numerical data: \\\n[magenta bold]{len(num_feats)}\"\n)\nprint()\nprint(\n    f\"[magenta]Number of features with categorical data: \\\n[magenta bold]{len(cat_feats)}\"\n)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T00:36:50.760520Z","iopub.execute_input":"2022-09-01T00:36:50.760980Z","iopub.status.idle":"2022-09-01T00:36:50.780541Z","shell.execute_reply.started":"2022-09-01T00:36:50.760941Z","shell.execute_reply":"2022-09-01T00:36:50.779512Z"},"trusted":true},"execution_count":206,"outputs":[]},{"cell_type":"code","source":"# Look at numeric data correlation\ncorr = df_cp[num_feats].corr(\"pearson\").round(2)\nmask_plot = np.triu(np.ones_like(corr, dtype=bool))\ndf_mask = corr.mask(mask_plot)\n\nfig = ff.create_annotated_heatmap(\n    z=df_mask.to_numpy(), \n    x=df_mask.columns.tolist(),\n    y=df_mask.columns.tolist(),\n    colorscale=px.colors.diverging.oxy,\n    showscale=True, \n    ygap=1, \n    xgap=1,\n)\n\nfig.update_xaxes(side=\"bottom\")\nfig.update_layout(\n    title_text=\"Correlation of numeric data by Pearson\", \n    title_x=0.5, \n    width=1300, \n    height=1000,\n    xaxis_showgrid=False,\n    yaxis_showgrid=False,\n    xaxis_zeroline=False,\n    yaxis_zeroline=False,\n    yaxis_autorange=\"reversed\",\n    template=\"plotly_white\"\n)\niplot(fig)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T00:36:57.576429Z","iopub.execute_input":"2022-09-01T00:36:57.577179Z","iopub.status.idle":"2022-09-01T00:37:01.138453Z","shell.execute_reply.started":"2022-09-01T00:36:57.577141Z","shell.execute_reply":"2022-09-01T00:37:01.136910Z"},"trusted":true},"execution_count":207,"outputs":[]},{"cell_type":"code","source":"# Considering specifics of sentiment analysis data, \n# let's delete data with correlation higher than 0.8\n\ndf_cp.drop([\"negrev_sia_neu\", \"pos_words_marker\",\n           \"negrev_sia_neg\", \"negrev_sia_pos\", \"negrev_sia_compound\", \n    \"posrev_sia_neg\", \"posrev_sia_neu\", \"posrev_sia_pos\", \"posrev_sia_compound\", ], axis=1, inplace=True) #","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T00:46:33.164779Z","iopub.execute_input":"2022-09-01T00:46:33.165229Z","iopub.status.idle":"2022-09-01T00:46:33.246459Z","shell.execute_reply.started":"2022-09-01T00:46:33.165195Z","shell.execute_reply":"2022-09-01T00:46:33.245091Z"},"trusted":true},"execution_count":216,"outputs":[]},{"cell_type":"code","source":"# Look at categorical data correlation\ncorr = df_cp[cat_feats].corr(\"spearman\").round(2)\nmask_plot = np.triu(np.ones_like(corr, dtype=bool))\ndf_mask = corr.mask(mask_plot)\n\nfig = ff.create_annotated_heatmap(\n    z=df_mask.to_numpy(), \n    x=df_mask.columns.tolist(),\n    y=df_mask.columns.tolist(),\n    colorscale=px.colors.diverging.oxy,\n    showscale=True, \n    ygap=1, \n    xgap=1,\n)\n\nfig.update_xaxes(side=\"bottom\")\nfig.update_layout(\n    title_text=\"Correlation of categorical data by Spearman\", \n    title_x=0.5, \n    width=1500, \n    height=1300,\n    xaxis_showgrid=False,\n    yaxis_showgrid=False,\n    xaxis_zeroline=False,\n    yaxis_zeroline=False,\n    yaxis_autorange=\"reversed\",\n    template=\"plotly_white\"\n)\niplot(fig)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-31T20:52:08.564887Z","iopub.execute_input":"2022-08-31T20:52:08.565278Z","iopub.status.idle":"2022-08-31T20:52:19.581146Z","shell.execute_reply.started":"2022-08-31T20:52:08.565241Z","shell.execute_reply":"2022-08-31T20:52:19.580016Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"# Delete data with correlation higher than 0.8\ndf_cp.drop([\"total_number_of_reviews\"], axis=1, inplace=True)\n\nprint(\n    f\"[magenta]Resulting number of features for model training: \\\n[magenta bold]{df_cp.shape[1]-2}\"\n)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T00:46:37.964193Z","iopub.execute_input":"2022-09-01T00:46:37.965021Z","iopub.status.idle":"2022-09-01T00:46:38.041341Z","shell.execute_reply.started":"2022-09-01T00:46:37.964980Z","shell.execute_reply":"2022-09-01T00:46:38.040088Z"},"trusted":true},"execution_count":217,"outputs":[]},{"cell_type":"code","source":"# Look at importance of features using ANOVA test\nX = df_cp.loc[df_cp[\"sample\"]==1].drop([\"sample\", \"reviewer_score\"], axis=1)\ny = df_cp.loc[df_cp[\"sample\"]==1, \"reviewer_score\"].values\n\n# There are negative values in data, so we can not use chi2 test\n# Use ANOVA for all features\nimp_feats = pd.Series(f_classif(X, y)[0], index = X.columns)\nimp_feats.sort_values(inplace = True)\n\nfig=px.bar(\n    imp_feats,\n    orientation=\"h\",\n    text_auto=\" .5s\",\n    height = 1400,\n    width=1400,\n    color=imp_feats.values,\n    title=\"Importance of features according to ANOVA test\",\n    labels={\"color\":\"Score range\"}\n)\nfig.update_layout(\n       font_family=\"Helvetica\",\n       xaxis=dict(tickfont_size=14, title=\"Score\"),\n       yaxis=dict(tickfont_size=12, title=\"Features\")\n)\nfig.update_traces(\n    textfont_size=12, \n    textangle=0, \n    textposition=\"outside\", \n    cliponaxis=False\n)\niplot(fig)\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T00:46:43.747272Z","iopub.execute_input":"2022-09-01T00:46:43.747737Z","iopub.status.idle":"2022-09-01T00:46:44.897279Z","shell.execute_reply.started":"2022-09-01T00:46:43.747700Z","shell.execute_reply":"2022-09-01T00:46:44.896017Z"},"trusted":true},"execution_count":218,"outputs":[]},{"cell_type":"code","source":"# Now let's remove features with score less than 3.5\nfeats_drop = [\n    \"room_type_junior\", \"room_type_club\", \"room_type_executive\",\n    \"room_type_family\", \"rev_type_travelers with friends\", \"pet_tag\",\n    \"roomX4\", \"rev_type_family with older children\", \"room_type_king\",\n    \"roomX2\"\n]\n#**********************************************************************72****79\ndf_cp.drop(feats_drop, axis=1, inplace=True)\nprint(\n    f\"[magenta]Resulting number of features for model training: \\\n[magenta bold]{df_cp.shape[1]-2}\"\n)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T00:37:44.806331Z","iopub.execute_input":"2022-09-01T00:37:44.807063Z","iopub.status.idle":"2022-09-01T00:37:44.894517Z","shell.execute_reply.started":"2022-09-01T00:37:44.807012Z","shell.execute_reply":"2022-09-01T00:37:44.893289Z"},"trusted":true},"execution_count":209,"outputs":[]},{"cell_type":"code","source":"# Allocate train and test parts\ntrain_data = df_cp.query(\"sample == 1\").drop([\"sample\"], axis=1)\ntest_data = df_cp.query(\"sample == 0\").drop([\"sample\"], axis=1)\n\ny = train_data.reviewer_score.values            # target feature\nX = train_data.drop([\"reviewer_score\"], axis=1)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T00:47:04.248606Z","iopub.execute_input":"2022-09-01T00:47:04.249035Z","iopub.status.idle":"2022-09-01T00:47:04.496249Z","shell.execute_reply.started":"2022-09-01T00:47:04.249001Z","shell.execute_reply":"2022-09-01T00:47:04.494937Z"},"trusted":true},"execution_count":219,"outputs":[]},{"cell_type":"code","source":"# Use train_test_split function for dividing data\n# Allocate 20% of data for validation\nX_train, X_test, y_train, y_test = train_test_split(\n                                     X, y, \n                                     test_size=0.2, \n                                     random_state=RANDOM_SEED\n)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T00:47:10.265546Z","iopub.execute_input":"2022-09-01T00:47:10.266490Z","iopub.status.idle":"2022-09-01T00:47:10.456291Z","shell.execute_reply.started":"2022-09-01T00:47:10.266440Z","shell.execute_reply":"2022-09-01T00:47:10.455119Z"},"trusted":true},"execution_count":220,"outputs":[]},{"cell_type":"code","source":"# Check result data\ntest_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T00:47:13.427382Z","iopub.execute_input":"2022-09-01T00:47:13.428327Z","iopub.status.idle":"2022-09-01T00:47:13.437372Z","shell.execute_reply.started":"2022-09-01T00:47:13.428264Z","shell.execute_reply":"2022-09-01T00:47:13.435850Z"},"trusted":true},"execution_count":221,"outputs":[]},{"cell_type":"code","source":"# Create model\nmodel = RandomForestRegressor(\n    n_estimators=100, \n    verbose=1, \n    n_jobs=-1, \n    random_state=RANDOM_SEED\n)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T00:47:18.071764Z","iopub.execute_input":"2022-09-01T00:47:18.072594Z","iopub.status.idle":"2022-09-01T00:47:18.089183Z","shell.execute_reply.started":"2022-09-01T00:47:18.072552Z","shell.execute_reply":"2022-09-01T00:47:18.087835Z"},"trusted":true},"execution_count":222,"outputs":[]},{"cell_type":"code","source":"%%time\n# Train model on train data\nmodel.fit(X_train, y_train)\n\n# Use pretrained model to predict scores of the hotels in test data\n# Write predictions into y_pred\ny_pred = model.predict(X_test)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T00:47:27.752274Z","iopub.execute_input":"2022-09-01T00:47:27.753381Z","iopub.status.idle":"2022-09-01T00:53:28.782551Z","shell.execute_reply.started":"2022-09-01T00:47:27.753328Z","shell.execute_reply":"2022-09-01T00:53:28.781148Z"},"trusted":true},"execution_count":223,"outputs":[]},{"cell_type":"code","source":"# Compare predicted values(y_pred) with real data(y_test) and how they differ\n# Use metric: Mean Absolute Percentage Error (MAPE)\nprint(\n    f\"[magenta]MAPE: \\\n[magenta bold]{round(metrics.mean_absolute_percentage_error(y_test, y_pred)*100, 5)}\"\n)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T00:45:57.515144Z","iopub.execute_input":"2022-09-01T00:45:57.515870Z","iopub.status.idle":"2022-09-01T00:45:57.526671Z","shell.execute_reply.started":"2022-09-01T00:45:57.515824Z","shell.execute_reply":"2022-09-01T00:45:57.525291Z"},"trusted":true},"execution_count":215,"outputs":[]},{"cell_type":"code","source":"# The most important features for model\nplt.rcParams[\"figure.figsize\"] = (15,15)\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(50).plot(kind=\"barh\", color=\"purple\")","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T00:15:05.960054Z","iopub.execute_input":"2022-09-01T00:15:05.960941Z","iopub.status.idle":"2022-09-01T00:15:07.387597Z","shell.execute_reply.started":"2022-09-01T00:15:05.960894Z","shell.execute_reply":"2022-09-01T00:15:07.386371Z"},"trusted":true},"execution_count":195,"outputs":[]},{"cell_type":"code","source":"# Predict target feature\ntest_data = test_data.drop(['reviewer_score'], axis=1)\npredict_submission = model.predict(test_data)\nsample_submission[\"reviewer_score\"] = predict_submission\nsample_submission.to_csv(\"submission.csv\", index=False)\nsample_submission.head(10)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T00:54:14.926154Z","iopub.execute_input":"2022-09-01T00:54:14.926648Z","iopub.status.idle":"2022-09-01T00:54:18.477526Z","shell.execute_reply.started":"2022-09-01T00:54:14.926608Z","shell.execute_reply":"2022-09-01T00:54:18.476368Z"},"trusted":true},"execution_count":224,"outputs":[]}]}